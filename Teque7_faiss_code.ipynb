{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-cohere (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-community (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-cohere (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-community (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-cohere (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-community (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-community faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-cohere (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-community (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-cohere (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-community (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-cohere (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-community (c:\\Users\\CHIRAG CHAWLA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "crewai 0.28.8 requires langchain<0.2.0,>=0.1.10, but you have langchain 0.3.13 which is incompatible.\n",
      "crewai-tools 0.1.6 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.3.13 which is incompatible.\n",
      "embedchain 0.1.113 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.3.13 which is incompatible.\n",
      "embedchain 0.1.113 requires langchain-openai<0.2.0,>=0.1.7, but you have langchain-openai 0.2.14 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain import hub\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch the API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY in the .env file\")\n",
    "\n",
    "# Use the OpenAI API key\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=openai_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your OpenAI API Key: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Fetch the API key from the environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Print the API key\n",
    "if openai_api_key:\n",
    "    print(f\"Your OpenAI API Key: {openai_api_key}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key is not set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"footwear_catalogue.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(file_path=pdf_path)\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30, separator=\"\\n\")\n",
    "split_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorstore = FAISS.from_documents(split_documents, embeddings)\n",
    "\n",
    "# Save the vector store\n",
    "vectorstore.save_local(\"footwear_data_huggingface_2.db\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorstore = FAISS.load_local(\"footwear_data_huggingface_2.db\", embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a refined prompt template\n",
    "# Load the LLM\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=\"\", \n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "You are a chatbot designed to answer questions based solely on the provided footwear catalog information. Your primary goal is to provide accurate, concise, and context-specific answers based on the information in the catalog.\n",
    "\n",
    "**Instructions:**\n",
    "1. Use only the content from the provided footwear catalog to generate responses.\n",
    "2. Do not generate information beyond what is available in the catalog.\n",
    "3. If you cannot find the answer to a question in the catalog, respond with:\n",
    "   *\"Sorry, I couldnâ€™t find the information you are looking for. Please check the catalog or contact the support team at office@eurosafetyfootwear.com.\"*\n",
    "\n",
    "**Footwear Catalog Details**\n",
    "{context}\n",
    "**End of Catalog Details**\n",
    "\n",
    "**Question:** {input}\n",
    "\n",
    "**Response:**\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.document_loaders import Docx2txtLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Create a chain for document retrieval and response generation\n",
    "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain = create_retrieval_chain(retriever, doc_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lining of the shoe of article No 104-23661-S3 is AEROSPACE MESH.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"Lining of the shoe of article No 104-23661-S3\"})\n",
    "\n",
    "# Get the Answer only\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, we have the DAKAER shoe in neon green color.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"Can you give me a shoe of neon green colour\"})\n",
    "\n",
    "# Get the Answer only\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "retriever = ...  # Your retriever\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "system_prompt = (\n",
    "    \"Use the given context to answer the question. \"\n",
    "    \"If you don't know the answer, say you don't know. \"\n",
    "    \"Use three sentence maximum and keep the answer concise. \"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "chain.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 17:52:31.942 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\CHIRAG CHAWLA\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you give me a shoe of green colour\"})\n",
    "st.write(response)  # Check the structure of the response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
